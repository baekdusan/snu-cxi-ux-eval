import json
import os
import re
import time
import hashlib
from pathlib import Path
from typing import List, Dict, Any, Optional
import datetime
from openai import OpenAI

from config import get_openai_client, DEFAULT_MODEL, VECTOR_INDEXING_WAIT_TIME


class FinalReportAgent:
    """ìµœì¢… ë ˆí¬íŠ¸ ìƒì„± ì—ì´ì „íŠ¸ - ëª¨ë“  í‰ê°€ ê²°ê³¼ë¥¼ AIê°€ ë¶„ì„í•˜ê³  í†µí•© (ë©€í‹°í„´ ëŒ€í™”í˜•)"""

    def __init__(self, api_key: Optional[str] = None):
        self.client = get_openai_client(api_key)
        self.model = DEFAULT_MODEL
        self.final_report_cache_file = Path(".final_report_vector_cache.json")
        
        # ë©€í‹°í„´ ëŒ€í™”ë¥¼ ìœ„í•œ ìƒíƒœ ê´€ë¦¬
        self.conversation_history: List[Dict[str, Any]] = []
        self.vector_store_id: Optional[str] = None
        self.evaluation_files: List[str] = []
        self.is_initialized: bool = False

    def _calculate_files_hash(self, file_paths: List[str]) -> str:
        """í‰ê°€ íŒŒì¼ë“¤ì˜ í•´ì‹œê°’ ê³„ì‚° (ìºì‹œ í‚¤ë¡œ ì‚¬ìš©)"""
        hasher = hashlib.md5()
        
        for file_path in sorted(file_paths):
            if os.path.exists(file_path):
                # íŒŒì¼ëª…ê³¼ ìˆ˜ì •ì‹œê°„ì„ í•´ì‹œì— í¬í•¨
                stat = os.stat(file_path)
                hasher.update(f"{file_path}:{stat.st_mtime}:{stat.st_size}".encode())
            else:
                hasher.update(f"{file_path}:missing".encode())
        
        return hasher.hexdigest()

    def _load_vector_cache(self, files_hash: str) -> Optional[str]:
        """ìºì‹œëœ ë²¡í„°ìŠ¤í† ì–´ ID ë¡œë“œ"""
        if not self.final_report_cache_file.exists():
            return None
        
        try:
            with open(self.final_report_cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            if cache_data.get('files_hash') == files_hash:
                vector_store_id = cache_data.get('vector_store_id')
                if vector_store_id:
                    print(f"âœ… ìºì‹œëœ í‰ê°€ ë²¡í„°ìŠ¤í† ì–´ ì¬ì‚¬ìš©: {vector_store_id}")
                    return vector_store_id
            
            print("ğŸ“ í‰ê°€ íŒŒì¼ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
            return None
            
        except Exception as e:
            print(f"âš ï¸ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    def _save_vector_cache(self, files_hash: str, vector_store_id: str) -> None:
        """ë²¡í„°ìŠ¤í† ì–´ IDë¥¼ ìºì‹œì— ì €ì¥"""
        try:
            cache_data = {
                'files_hash': files_hash,
                'vector_store_id': vector_store_id,
                'created_at': datetime.datetime.now().isoformat()
            }
            
            with open(self.final_report_cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ í‰ê°€ ë²¡í„°ìŠ¤í† ì–´ ìºì‹œ ì €ì¥ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âš ï¸ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")

    def initialize_with_files(self, evaluation_files: List[str]) -> str:
        """í‰ê°€ íŒŒì¼ë“¤ì„ ë¡œë“œí•˜ê³  ë©€í‹°í„´ ëŒ€í™” ì¤€ë¹„"""
        if not evaluation_files:
            return "âŒ í‰ê°€ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."

        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        valid_files = [f for f in evaluation_files if os.path.exists(f)]
        if not valid_files:
            return "âŒ ì½ì„ ìˆ˜ ìˆëŠ” í‰ê°€ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."

        try:
            self.evaluation_files = valid_files
            
            # íŒŒì¼ í•´ì‹œ ê³„ì‚° ë° ìºì‹œ í™•ì¸
            files_hash = self._calculate_files_hash(valid_files)
            cached_vector_store_id = self._load_vector_cache(files_hash)
            
            if cached_vector_store_id:
                # ìºì‹œëœ ë²¡í„°ìŠ¤í† ì–´ ì‚¬ìš©
                self.vector_store_id = cached_vector_store_id
            else:
                # ìƒˆ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
                print("=== í‰ê°€ ê²°ê³¼ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì‹œì‘ ===")
                
                # íŒŒì¼ ì—…ë¡œë“œ
                uploaded_files = []
                for file_path in valid_files:
                    with open(file_path, "rb") as f:
                        uploaded_file = self.client.files.create(
                            file=f,
                            purpose="assistants"
                        )
                        uploaded_files.append(uploaded_file.id)
                        print(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {os.path.basename(file_path)} (ID: {uploaded_file.id})")

                # ë²¡í„°ìŠ¤í† ì–´ ìƒì„± í›„ íŒŒì¼ ì¶”ê°€
                vs = self.client.vector_stores.create(name="Final Report Evaluation Data")
                self.vector_store_id = vs.id
                for file_id in uploaded_files:
                    self.client.vector_stores.files.create(vector_store_id=self.vector_store_id, file_id=file_id)
                print(f"ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ: {self.vector_store_id}")

                # ìºì‹œ ì €ì¥
                self._save_vector_cache(files_hash, self.vector_store_id)
                
                # ì¸ë±ì‹± ëŒ€ê¸°
                time.sleep(VECTOR_INDEXING_WAIT_TIME)

            self.is_initialized = True
            file_list = ", ".join([os.path.basename(f) for f in valid_files])
            
            return f"âœ… **Final Report Agent ì¤€ë¹„ ì™„ë£Œ!**\n\nğŸ“ **ë¡œë“œëœ í‰ê°€ íŒŒì¼**: {file_list}\n\nğŸ’¬ **ì´ì œ í‰ê°€ ê²°ê³¼ì— ëŒ€í•´ ììœ ë¡­ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”:**\n- ê°€ì¥ ì‹¬ê°í•œ ë¬¸ì œëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n- ìš°ì„ ìˆœìœ„ë³„ ê°œì„  ì‚¬í•­ì„ ì•Œë ¤ì£¼ì„¸ìš”\n- ê° ì—ì´ì „íŠ¸ë³„ ì£¼ìš” ë°œê²¬ì‚¬í•­ì€?\n- ì‚¬ìš©ì ê²½í—˜ ê°œì„  ë°©í–¥ ì œì‹œí•´ì£¼ì„¸ìš”"

        except Exception as e:
            return f"âŒ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

    def chat(self, user_message: str) -> str:
        """ì‚¬ìš©ìì™€ì˜ ë©€í‹°í„´ ëŒ€í™” ì²˜ë¦¬"""
        if not self.is_initialized:
            return "âŒ ë¨¼ì € í‰ê°€ íŒŒì¼ë“¤ì„ ë¡œë“œí•´ì£¼ì„¸ìš”."
        
        if not user_message.strip():
            return "ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."

        try:
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (í‰ê°€ ë°ì´í„° ì „ë¬¸ê°€ ì—­í• )
            system_prompt = """ë‹¹ì‹ ì€ UX/UI í‰ê°€ ê²°ê³¼ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì²¨ë¶€ëœ í‰ê°€ íŒŒì¼ë“¤ì— ëŒ€í•´ file_search ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , 
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

ì¤‘ìš”í•œ ì›ì¹™:
- ë°˜ë“œì‹œ file_searchë¡œ ê²€ìƒ‰í•œ ì‹¤ì œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€
- ì¶”ì¸¡ì´ë‚˜ ì¼ë°˜ë¡ ì´ ì•„ë‹Œ êµ¬ì²´ì ì¸ í‰ê°€ ê²°ê³¼ ì¸ìš©
- ê°œì„  ì œì•ˆ ì‹œ ìš°ì„ ìˆœìœ„ì™€ êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ì•ˆ ì œì‹œ
- ì „ë¬¸ì ì´ì§€ë§Œ ì´í•´í•˜ê¸° ì‰¬ìš´ ì–¸ì–´ë¡œ ì„¤ëª…"""

            # ì…ë ¥ ë©”ì‹œì§€ êµ¬ì„±
            input_messages: List[Dict[str, Any]] = []
            
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€
            input_messages.append({
                "role": "system",
                "content": [{"type": "input_text", "text": system_prompt}]
            })
            
            # ê¸°ì¡´ ëŒ€í™” íˆìŠ¤í† ë¦¬
            input_messages.extend(self.conversation_history)
            
            # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€
            current_message = {
                "role": "user", 
                "content": [{"type": "input_text", "text": user_message}]
            }
            input_messages.append(current_message)

            # Responses API í˜¸ì¶œ (file_search í™œì„±í™”)
            response = self.client.responses.create(
                model=self.model,
                input=input_messages,
                tools=[{
                    "type": "file_search",
                    "vector_store_ids": [self.vector_store_id]
                }]
            )

            ai_response = response.output_text
            
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.conversation_history.append(current_message)
            self.conversation_history.append({
                "role": "assistant",
                "content": [{"type": "output_text", "text": ai_response}]
            })

            return ai_response

        except Exception as e:
            return f"âŒ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

    def reset_conversation(self):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” (í‰ê°€ ë°ì´í„°ëŠ” ìœ ì§€)"""
        self.conversation_history.clear()
        print("Final Report Agent ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”")

    def clear_all(self):
        """ëª¨ë“  ìƒíƒœ ì´ˆê¸°í™”"""
        self.conversation_history.clear()
        self.vector_store_id = None
        self.evaluation_files.clear()
        self.is_initialized = False
        print("Final Report Agent ì™„ì „ ì´ˆê¸°í™”")

    def generate_final_report_json(self) -> Dict[str, Any]:
        """êµ¬ì¡°í™”ëœ JSON ë ˆí¬íŠ¸ ìƒì„± (ë ˆê±°ì‹œ í˜¸í™˜)"""
        if not self.is_initialized:
            return {"error": "Agent not initialized"}
        
        report_request = "ëª¨ë“  í‰ê°€ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:\n\n{\n  \"summary\": \"ì „ì²´ ìš”ì•½\",\n  \"critical_issues\": [\"ì‹¬ê°í•œ ë¬¸ì œë“¤\"],\n  \"recommendations\": [\"ê°œì„  ì œì•ˆë“¤\"],\n  \"priority_matrix\": \"ìš°ì„ ìˆœìœ„ë³„ ì‹¤í–‰ ê³„íš\"\n}\n\nJSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”."
        
        response = self.chat(report_request)
        
        # JSON ì¶”ì¶œ ì‹œë„
        try:
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
            start = response.find('{')
            end = response.rfind('}') + 1
            if start != -1 and end > start:
                json_str = response[start:end]
                return json.loads(json_str)
            else:
                return {"raw_response": response}
        except json.JSONDecodeError:
            return {"raw_response": response}

    def save_report(self, report: Dict[str, Any], output_dir: str = "output") -> str:
        """ìµœì¢… ë ˆí¬íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"final_report_{timestamp}.json"
        file_path = os.path.join(output_dir, filename)

        os.makedirs(output_dir, exist_ok=True)

        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        return file_path