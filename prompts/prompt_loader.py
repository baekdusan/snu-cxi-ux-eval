import re
import json
import hashlib
from pathlib import Path
from typing import Optional, Dict
from openai import OpenAI

from config import get_openai_client

# íŒŒì¼ ì½ê¸° ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    import docx  # python-docx ë¼ì´ë¸ŒëŸ¬ë¦¬
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False

try:
    import markdown  # markdown ë¼ì´ë¸ŒëŸ¬ë¦¬
    MARKDOWN_AVAILABLE = True
except ImportError:
    MARKDOWN_AVAILABLE = False

class SimplePromptLoader:
    """ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ ë¡œë” - Python íŒŒì¼ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬"""
    
    def __init__(self):
        self.prompts_dir = Path("prompts/")
        self.refs_dir = Path("references/")  # ë£¨íŠ¸ ë ˆë²¨ references í´ë”
        self.cache_file = Path(".vector_store_cache.json")  # ë²¡í„°ìŠ¤í† ì–´ ìºì‹œ íŒŒì¼
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (í™˜ê²½ë³€ìˆ˜ê°€ ìˆì„ ë•Œë§Œ ì‹œë„)
        try:
            self.client = get_openai_client()
        except ValueError:
            self.client = None
            print("ê²½ê³ : OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë²¡í„°ìŠ¤í† ì–´ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì—ì´ì „íŠ¸ë³„ ì°¸ì¡° ë¬¸ì„œ ë§¤í•‘ (ë²¡í„°ìŠ¤í† ì–´ìš©)
        self.reference_mapping = {
            "Text Legibility": ["Agent1_Text_heuristics.md"],
            "Information Architecture": ["Agent2_Terms_and_definitions.md", "Agent2_IA_heuristics.md"],
            "Icon Representativeness": ["Agent3_Icon_heuristics.md"],
            "User Task Suitability": ["Agent4_Terms_and_definitions.md", "Agent4_heuristics.md"]
        }
        
        # ë²¡í„°ìŠ¤í† ì–´ ê´€ë ¨ ì†ì„±
        self.vector_store = None
        self.file_to_vector_store_mapping = {}  # íŒŒì¼ëª… -> ë²¡í„°ìŠ¤í† ì–´ ID ë§¤í•‘
        self._vector_store_initialized = False  # ì´ˆê¸°í™” ìƒíƒœ ì¶”ì 
        
        # ìºì‹œ ë¡œë“œ
        self._load_cache()
    
    def _calculate_files_hash(self) -> str:
        """ì°¸ì¡° íŒŒì¼ë“¤ì˜ í•´ì‹œê°’ ê³„ì‚° (íŒŒì¼ ë³€ê²½ ê°ì§€ìš©)"""
        hasher = hashlib.md5()
        
        # ëª¨ë“  ì°¸ì¡° íŒŒì¼ ìˆ˜ì§‘ (ì¤‘ë³µ ì œê±°)
        all_files = set()
        for agent_files in self.reference_mapping.values():
            for filename in agent_files:
                all_files.add(filename)
        
        # íŒŒì¼ë“¤ì„ ì •ë ¬ëœ ìˆœì„œë¡œ í•´ì‹œì— ì¶”ê°€
        for filename in sorted(all_files):
            file_path = self.refs_dir / filename
            if file_path.exists():
                # íŒŒì¼ëª…ê³¼ ìˆ˜ì •ì‹œê°„ì„ í•´ì‹œì— í¬í•¨
                hasher.update(f"{filename}:{file_path.stat().st_mtime}".encode())
            else:
                hasher.update(f"{filename}:missing".encode())
        
        return hasher.hexdigest()
    
    def _load_cache(self) -> None:
        """ìºì‹œ íŒŒì¼ì—ì„œ ë²¡í„°ìŠ¤í† ì–´ ì •ë³´ ë¡œë“œ"""
        if not self.cache_file.exists():
            return
        
        try:
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            # íŒŒì¼ í•´ì‹œ ê²€ì¦
            current_hash = self._calculate_files_hash()
            cached_hash = cache_data.get('files_hash', '')
            
            if current_hash == cached_hash:
                # íŒŒì¼ì´ ë³€ê²½ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ìºì‹œëœ ë²¡í„°ìŠ¤í† ì–´ ì •ë³´ ì‚¬ìš©
                self.vector_store_id = cache_data.get('vector_store_id')
                self.file_to_vector_store_mapping = cache_data.get('file_mapping', {})
                if self.vector_store_id:
                    self._vector_store_initialized = True
                    print(f"âœ… ìºì‹œëœ ë²¡í„°ìŠ¤í† ì–´ ì¬ì‚¬ìš©: {self.vector_store_id}")
                    return
            
            print("ğŸ“ ì°¸ì¡° íŒŒì¼ì´ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ìºì‹œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            
        except Exception as e:
            print(f"âš ï¸ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _save_cache(self) -> None:
        """ë²¡í„°ìŠ¤í† ì–´ ì •ë³´ë¥¼ ìºì‹œ íŒŒì¼ì— ì €ì¥"""
        try:
            cache_data = {
                'vector_store_id': getattr(self, 'vector_store_id', None),
                'files_hash': self._calculate_files_hash(),
                'file_mapping': self.file_to_vector_store_mapping
            }
            
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ ë²¡í„°ìŠ¤í† ì–´ ìºì‹œ ì €ì¥ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âš ï¸ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def load_prompt(self, agent_type: str, agent_name: str) -> str:
        """ì—ì´ì „íŠ¸ íƒ€ì…ê³¼ ì´ë¦„ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ (ëª¨ë“  ì—ì´ì „íŠ¸ Markdown ì‚¬ìš©)"""
        try:
            # ëª¨ë“  ì—ì´ì „íŠ¸ê°€ Markdown íŒŒì¼ ì‚¬ìš©
            agent_num = self._get_agent_number(agent_name)
            if agent_type == "dr_generator":
                md_file = f"Agent{agent_num}_DR_prompt.md"
            elif agent_type == "evaluator":
                md_file = f"Agent{agent_num}_E_prompt.md"
            else:
                raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ì—ì´ì „íŠ¸ íƒ€ì…: {agent_type}")
            
            prompt_text = self._read_markdown_prompt(md_file)
            
            # í”„ë¡¬í”„íŠ¸ ì›ë³¸ ê·¸ëŒ€ë¡œ ë°˜í™˜ (file_searchê°€ ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ê´€ë ¨ ë‚´ìš© ìë™ ê²€ìƒ‰)
            return prompt_text
            
        except Exception as e:
            print(f"í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return f"í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}"
    
    def _get_agent_number(self, agent_name: str) -> str:
        """ì—ì´ì „íŠ¸ ì´ë¦„ì„ ìˆ«ìë¡œ ë§¤í•‘"""
        mapping = {
            "Text Legibility": "1",
            "Information Architecture": "2",
            "Icon Representativeness": "3", 
            "User Task Suitability": "4"
        }
        if agent_name not in mapping:
            raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ì—ì´ì „íŠ¸: {agent_name}")
        return mapping[agent_name]
    
    def _read_markdown_prompt(self, filename: str) -> str:
        """Markdown í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì½ê¸°"""
        file_path = self.prompts_dir / filename
        if not file_path.exists():
            raise FileNotFoundError(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {filename}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            raise Exception(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ({filename}): {str(e)}")
    
    
    def _read_docx_file(self, file_path: Path) -> str:
        """DOCX íŒŒì¼ ì½ê¸°"""
        if not DOCX_AVAILABLE:
            return f"[python-docx ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ: {file_path.name}]"
        
        try:
            doc = docx.Document(file_path)
            text = []
            for paragraph in doc.paragraphs:
                text.append(paragraph.text)
            return '\n'.join(text)
        except Exception as e:
            return f"[DOCX íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {file_path.name}, {str(e)}]"
    
    def _read_markdown_file(self, file_path: Path) -> str:
        """Markdown íŒŒì¼ ì½ê¸° (HTMLë¡œ ë³€í™˜ í›„ í…ìŠ¤íŠ¸ ì¶”ì¶œ)"""
        if not MARKDOWN_AVAILABLE:
            return f"[markdown ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ: {file_path.name}]"
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                md_content = f.read()
            
            # Markdownì„ HTMLë¡œ ë³€í™˜
            html = markdown.markdown(md_content)
            
            # HTML íƒœê·¸ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
            import re
            text = re.sub(r'<[^>]+>', '', html)
            return text
        except Exception as e:
            return f"[Markdown íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {file_path.name}, {str(e)}]"
    
    
    def create_vector_store(self) -> str:
        """ì°¸ì¡° íŒŒì¼ë“¤ì„ ë²¡í„°ìŠ¤í† ì–´ì— ì—…ë¡œë“œí•˜ê³  ë²¡í„°ìŠ¤í† ì–´ ID ë°˜í™˜"""
        if not self.client:
            print("ì˜¤ë¥˜: OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
            
        try:
            # ìºì‹œëœ ë²¡í„°ìŠ¤í† ì–´ê°€ ìˆìœ¼ë©´ ì¬ì‚¬ìš©
            if self._vector_store_initialized and hasattr(self, 'vector_store_id'):
                print(f"âœ… ìºì‹œëœ ë²¡í„°ìŠ¤í† ì–´ ì¬ì‚¬ìš©: {self.vector_store_id}")
                return self.vector_store_id
            
            print("=== ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ë° íŒŒì¼ ì—…ë¡œë“œ ì‹œì‘ ===")
            
            # ìƒˆ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
            self.vector_store = self.client.vector_stores.create(
                name="UX Guidelines Reference Documents"
            )
            self.vector_store_id = self.vector_store.id
            print(f"ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ: {self.vector_store_id}")
            
            # ëª¨ë“  ì°¸ì¡° íŒŒì¼ ìˆ˜ì§‘ (ì¤‘ë³µ ì œê±°)
            all_files = set()
            for agent_files in self.reference_mapping.values():
                for filename in agent_files:
                    all_files.add(filename)
            
            print(f"ì—…ë¡œë“œí•  íŒŒì¼ ëª©ë¡: {list(all_files)}")
            
            # íŒŒì¼ë“¤ì„ ë²¡í„°ìŠ¤í† ì–´ì— ì—…ë¡œë“œ
            uploaded_count = 0
            for filename in all_files:
                file_path = self.refs_dir / filename
                if file_path.exists():
                    try:
                        print(f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘: {filename}")
                        with open(file_path, 'rb') as f:
                            # OpenAIì— íŒŒì¼ ì—…ë¡œë“œ
                            uploaded_file = self.client.files.create(
                                file=f,
                                purpose='assistants'
                            )
                            
                            # ë²¡í„°ìŠ¤í† ì–´ì— íŒŒì¼ ì¶”ê°€
                            self.client.vector_stores.files.create(
                                vector_store_id=self.vector_store_id,
                                file_id=uploaded_file.id
                            )
                            
                            # ë§¤í•‘ í…Œì´ë¸”ì— ì¶”ê°€
                            self.file_to_vector_store_mapping[filename] = uploaded_file.id
                            print(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {filename} -> {uploaded_file.id}")
                            uploaded_count += 1
                            
                    except Exception as e:
                        print(f"âŒ íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {filename}, ì˜¤ë¥˜: {e}")
                else:
                    print(f"âš ï¸  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_path}")
            
            # ì´ˆê¸°í™” ì™„ë£Œ í‘œì‹œ ë° ìºì‹œ ì €ì¥
            self._vector_store_initialized = True
            self._save_cache()
            print(f"=== ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™” ì™„ë£Œ: {uploaded_count}ê°œ íŒŒì¼ ì—…ë¡œë“œ ===")
            
            return self.vector_store_id
            
        except Exception as e:
            print(f"âŒ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def get_vector_store_id(self) -> Optional[str]:
        """ë²¡í„°ìŠ¤í† ì–´ ID ë°˜í™˜ (ì—†ìœ¼ë©´ ìƒì„±)"""
        if self._vector_store_initialized and hasattr(self, 'vector_store_id'):
            return self.vector_store_id
        return self.create_vector_store()
    
    def get_file_mapping(self) -> Dict[str, str]:
        """íŒŒì¼ëª… -> ë²¡í„°ìŠ¤í† ì–´ íŒŒì¼ ID ë§¤í•‘ ë°˜í™˜"""
        return self.file_to_vector_store_mapping.copy()
    
    def is_file_uploaded(self, filename: str) -> bool:
        """íŠ¹ì • íŒŒì¼ì´ ë²¡í„°ìŠ¤í† ì–´ì— ì—…ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        return filename in self.file_to_vector_store_mapping
    
    def initialize_vector_store_if_needed(self) -> bool:
        """í•„ìš”ì‹œ ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™” (ìµœì´ˆ í•œë²ˆë§Œ)"""
        if not self._vector_store_initialized:
            vector_store_id = self.create_vector_store()
            return vector_store_id is not None
        return True
    
    # ë ˆê±°ì‹œ ë©”ì„œë“œ - í˜„ì¬ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
    # def get_available_prompts(self, agent_type: str) -> list:
    #     """ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ ëª©ë¡ ë°˜í™˜ (ë ˆê±°ì‹œ)"""
    #     pass 